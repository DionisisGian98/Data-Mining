# -*- coding: utf-8 -*-
"""Untitled63.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F7JgWwAFhcUIGqNNES6lg_ZOlwVeDoFI
"""

import pandas as pd
from sklearn.impute import KNNImputer
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn import preprocessing
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import VarianceThreshold
from sklearn.model_selection import GridSearchCV
from sklearn.decomposition import PCA
from imblearn.over_sampling import RandomOverSampler

df = pd.read_csv('healthcare-dataset-stroke-data.csv')
print("Check Null entries")
print(df.isnull().sum())
print()

def fixNull(df, method):
  # useless for prediction
      df = df.drop('id', axis=1) # remove column id
      numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
      categorical = df.select_dtypes(exclude=numerics)
      categorical_list = list(categorical.columns)
      label_encoder = preprocessing.LabelEncoder()

      for c in categorical_list:
        df[c] = label_encoder.fit_transform(df[c])# Convert categorical features
      if method == 'del':
          # Drop columns with NaN
          df = df.drop('bmi', axis=1)
      elif method == 'mean':
          # Replace with mean
          df['bmi'].fillna((df['bmi'].mean()), inplace=True)
      elif method == 'LR':
            # Replace with linear interpolation
            df['bmi'] = df['bmi'].interpolate(method='linear', limit_direction='both')
      elif method == 'kNN':
            #Replace with KNN values
            knn_imp = KNNImputer(n_neighbors=5, weights='uniform')
            df['bmi'] = knn_imp.fit_transform(df)
      return df


def SVM(df):
    temp_df = df.drop(['stroke'], axis=1)
  
    y = df['stroke']
    X = temp_df
    print(X)
    # train && test data
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
    scaler = StandardScaler()
    selector = VarianceThreshold()
    pca = PCA()
    oversamp = RandomOverSampler(random_state=1)
    
    param_grid = {'clf__C': [0.01, 0.1, 0.5, 1, 10, 100],
                    'selector__threshold' : [0, 1e-2, 3e-2, 4e-2, 5e-2,6e-2,7e-2,8e-2,9e-2],
                    'pca__n_components'   : [None, 0.95, 0.96, 0.97, 0.98, 0.99],
                    'clf__gamma': ['auto','scale',1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001],
                     'clf__kernel': ['rbf', 'poly', 'linear','sigmoid']}

    #Ορίζω το Pipe του RandomForest 
    pipeline = Pipeline(steps=[('scaler', scaler), ('selector', selector), ('pca', pca),("clf",SVC())])
    # initialize
    grid_pipeline = GridSearchCV(pipeline,param_grid=param_grid, cv=3, n_jobs=-1,verbose=1)
    # fit
    grid_pipeline.fit(x_train,y_train)
    best_model = grid_pipeline.best_estimator_
    best_params = grid_pipeline.best_params_
    
    y_pred = grid_pipeline.predict(x_test.values) # make the predictions
    best_model = grid_pipeline.best_estimator_['clf'].fit(X, y)
    predictions = best_model.predict(x_train)
    
    print('F1: {0:.2f}%,   Precision: {1:.2f}%,   Recall: {2:.2f}%'.format(f1_score(y_test, y_pred, average='macro') * 100,
          precision_score(y_test, y_pred, average='macro') * 100, recall_score(y_test, y_pred, average='macro') * 100))

deleted_nan_values = fixNull(df,'del')
mean_nan_values = fixNull(df,'mean')
lr_nan_values = fixNull(df,'LR')
knn_nan_values = fixNull(df,'kNN')

SVM(deleted_nan_values)
SVM(mean_nan_values)
SVM(lr_nan_values)
SVM(knn_nan_values)